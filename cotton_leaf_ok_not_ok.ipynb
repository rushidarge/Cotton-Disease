{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cotton leaf ok not ok",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjJNa5thSJK-",
        "outputId": "f1205d80-0890-4708-ec11-23bab8cca516"
      },
      "source": [
        "cd /content/drive/MyDrive/cotton leaf"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/cotton leaf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-shficGSdSC"
      },
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "# Importing the Keras libraries and packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYYIgLd4SmF7"
      },
      "source": [
        "classifier = Sequential()\n",
        "\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
        "\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "classifier.add(Flatten())\n",
        "\n",
        "classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q6eRNsuSp3m"
      },
      "source": [
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxMG9QPGSsKL",
        "outputId": "fc572fb3-51c0-497a-b520-7e101c9016cb"
      },
      "source": [
        "# augmenting train set\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
        "\n",
        "# augmenting test set\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "##apply image augmentation on train set by resizing all images to 64x64 and creating batches of 32 images.\n",
        "training_set = train_datagen.flow_from_directory('train',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')\n",
        "\n",
        "# apply image augmentation on test set by resizing all images to 64x64 and creating batches of 32 images.\n",
        "test_set = test_datagen.flow_from_directory('test', target_size = (64, 64), batch_size = 32, class_mode = 'binary')\n",
        "\n",
        "\n",
        "###steps_per_epoch: num of data divided by batch size\n",
        "###validation_steps: num of data divided by batch size\n",
        "classifier.fit_generator(training_set, steps_per_epoch = (346/16), epochs = 12, validation_data = test_set, validation_steps = (3/1))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 715 images belonging to 2 classes.\n",
            "Found 8 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "22/21 [==============================] - ETA: -3s - loss: 1.4445 - accuracy: 0.5577WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3.0 batches). You may need to use the repeat() function when building your dataset.\n",
            "21/21 [==============================] - 247s 10s/step - loss: 1.4300 - accuracy: 0.5571 - val_loss: 0.7075 - val_accuracy: 0.6250\n",
            "Epoch 2/12\n",
            "21/21 [==============================] - 6s 267ms/step - loss: 0.6717 - accuracy: 0.6428\n",
            "Epoch 3/12\n",
            "21/21 [==============================] - 5s 253ms/step - loss: 0.5226 - accuracy: 0.7924\n",
            "Epoch 4/12\n",
            "21/21 [==============================] - 5s 251ms/step - loss: 0.4452 - accuracy: 0.8046\n",
            "Epoch 5/12\n",
            "21/21 [==============================] - 5s 253ms/step - loss: 0.3719 - accuracy: 0.8386\n",
            "Epoch 6/12\n",
            "21/21 [==============================] - 5s 254ms/step - loss: 0.3688 - accuracy: 0.8400\n",
            "Epoch 7/12\n",
            "21/21 [==============================] - 6s 255ms/step - loss: 0.3125 - accuracy: 0.8805\n",
            "Epoch 8/12\n",
            "21/21 [==============================] - 5s 254ms/step - loss: 0.3059 - accuracy: 0.8709\n",
            "Epoch 9/12\n",
            "21/21 [==============================] - 6s 254ms/step - loss: 0.3001 - accuracy: 0.8839\n",
            "Epoch 10/12\n",
            "21/21 [==============================] - 5s 252ms/step - loss: 0.2728 - accuracy: 0.9027\n",
            "Epoch 11/12\n",
            "21/21 [==============================] - 5s 250ms/step - loss: 0.2685 - accuracy: 0.9024\n",
            "Epoch 12/12\n",
            "21/21 [==============================] - 5s 248ms/step - loss: 0.2710 - accuracy: 0.9021\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fae2ec41dd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUqXEwUcUuUU",
        "outputId": "cf2ced36-16e0-4117-ae10-be93147936b2"
      },
      "source": [
        "test_image = image.load_img('test/fresh cotton leaf/d (341).jpg', target_size = (64, 64))\n",
        "#add channel dimension for image\n",
        "test_image = image.img_to_array(test_image)\n",
        "\n",
        "##add batch dimension for image\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "\n",
        "result = classifier.predict(test_image)\n",
        "\n",
        "training_set.class_indices\n",
        "\n",
        "if result[0][0] == 1:\n",
        "    print('fresh cotton leaf')\n",
        "else:\n",
        "    print('diseased cotton leaf')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fresh cotton leaf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGWYHFqRWcaz",
        "outputId": "0e4d49e1-26ad-4af2-a4b3-49b84efaa93e"
      },
      "source": [
        "training_set.class_indices"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'diseased cotton leaf': 0, 'fresh cotton leaf': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_OPein4Lour"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "classifier.save('NN_cotton_leaf_binary_model.h5')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beBfCzLxLGXO",
        "outputId": "3f57d561-d937-44e5-cd69-7f6f38a94936"
      },
      "source": [
        "ls"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cotton_leaf_binary_model.h5  model.json  NN_cotton_leaf_binary_model.h5  \u001b[0m\u001b[01;34mtrain\u001b[0m/\n",
            "model.h5                     m.txt       \u001b[01;34mtest\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCLn7ApqL1tt"
      },
      "source": [
        "model = load_model('NN_cotton_leaf_binary_model.h5')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzZLqcVsL6PV",
        "outputId": "9d781af9-4cba-4421-9bb6-43cf45cd4397"
      },
      "source": [
        "test_image = image.load_img('test/fresh cotton leaf/d (341).jpg', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "model.predict(test_image)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    }
  ]
}